{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e6ab09",
   "metadata": {},
   "source": [
    "# A deep dive into robomimic datasets\n",
    "\n",
    "This notebook will provide examples on how to work with robomimic datasets through various python code examples. This notebook assumes that you have installed `robomimic` and `robosuite` (which should be on the `offline_study` branch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753a7db2-a1e8-483d-9414-36bd5712f5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No private macro file found!\n",
      "    It is recommended to use a private macro file\n",
      "    To setup, run: python /proj/vondrick3/sruthi/robots/robomimic/robomimic/scripts/setup_macros.py\n",
      ")\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import robomimic\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "\n",
    "# the dataset registry can be found at robomimic/__init__.py\n",
    "from robomimic import DATASET_REGISTRY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a05e543",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "First, let's try downloading a simple dataset - we'll use the Lift (PH) dataset. Note that there are utility scripts such as `scripts/download_datasets.py` to do this for us, but for the purposes of this example, we'll use the python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2b90e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "low_dim_v141.hdf5: 21.7MB [00:01, 16.8MB/s]                                                                                                                                                   \n"
     ]
    }
   ],
   "source": [
    "# set download folder and make it\n",
    "download_folder = \"/tmp/robomimic_ds_example\"\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "# download the dataset\n",
    "task = \"lift\"\n",
    "dataset_type = \"ph\"\n",
    "hdf5_type = \"low_dim\"\n",
    "FileUtils.download_url(\n",
    "    url=DATASET_REGISTRY[task][dataset_type][hdf5_type][\"url\"], \n",
    "    download_dir=download_folder,\n",
    ")\n",
    "\n",
    "# enforce that the dataset exists\n",
    "dataset_path = os.path.join(download_folder, \"low_dim_v141.hdf5\")\n",
    "assert os.path.exists(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bdec82",
   "metadata": {},
   "source": [
    "## Read quantities from dataset\n",
    "\n",
    "Next, let's demonstrate how to read different quantities from the dataset. There are scripts such as `scripts/get_dataset_info.py` that can help you easily understand the contents of a dataset, but in this example, we'll break down how to do this directly.\n",
    "\n",
    "First, let's take a look at the number of demonstrations in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35cd8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 file /proj/vondrick3/sruthi/robots/robomimic/datasets/lift_real/ph/demo.hdf5 has 200 demonstrations\n"
     ]
    }
   ],
   "source": [
    "download_folder = \"/proj/vondrick3/sruthi/robots/robomimic/test_dataset\"\n",
    "dataset_path = '/proj/vondrick3/sruthi/robots/robomimic/datasets/lift_real/ph/demo.hdf5'\n",
    "# open file\n",
    "f = h5py.File(dataset_path, \"r\")\n",
    "\n",
    "# each demonstration is a group under \"data\"\n",
    "demos = list(f[\"data\"].keys())\n",
    "num_demos = len(demos)\n",
    "\n",
    "print(\"hdf5 file {} has {} demonstrations\".format(dataset_path, num_demos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b21f8fd-da60-4349-b278-50c1d2e64b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['actions', 'dones', 'interventions', 'next_obs', 'obs', 'policy_acting', 'rewards', 'states', 'user_acting']>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"data\"]['demo_0'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb073a0",
   "metadata": {},
   "source": [
    "Next, let's list all of the demonstrations, along with the number of state-action pairs in each demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bda3e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_0 has 66 samples\n",
      "demo_1 has 57 samples\n",
      "demo_2 has 58 samples\n",
      "demo_3 has 64 samples\n",
      "demo_4 has 67 samples\n",
      "demo_5 has 58 samples\n",
      "demo_6 has 60 samples\n",
      "demo_7 has 57 samples\n",
      "demo_8 has 56 samples\n",
      "demo_9 has 54 samples\n",
      "demo_10 has 54 samples\n",
      "demo_11 has 55 samples\n",
      "demo_12 has 57 samples\n",
      "demo_13 has 53 samples\n",
      "demo_14 has 47 samples\n",
      "demo_15 has 50 samples\n",
      "demo_16 has 56 samples\n",
      "demo_17 has 58 samples\n",
      "demo_18 has 58 samples\n",
      "demo_19 has 57 samples\n",
      "demo_20 has 57 samples\n",
      "demo_21 has 75 samples\n",
      "demo_22 has 66 samples\n",
      "demo_23 has 56 samples\n",
      "demo_24 has 61 samples\n",
      "demo_25 has 64 samples\n",
      "demo_26 has 54 samples\n",
      "demo_27 has 51 samples\n",
      "demo_28 has 59 samples\n",
      "demo_29 has 48 samples\n",
      "demo_30 has 54 samples\n",
      "demo_31 has 61 samples\n",
      "demo_32 has 55 samples\n",
      "demo_33 has 54 samples\n",
      "demo_34 has 49 samples\n",
      "demo_35 has 57 samples\n",
      "demo_36 has 51 samples\n",
      "demo_37 has 54 samples\n",
      "demo_38 has 56 samples\n",
      "demo_39 has 60 samples\n",
      "demo_40 has 56 samples\n",
      "demo_41 has 47 samples\n",
      "demo_42 has 57 samples\n",
      "demo_43 has 45 samples\n",
      "demo_44 has 53 samples\n",
      "demo_45 has 60 samples\n",
      "demo_46 has 55 samples\n",
      "demo_47 has 47 samples\n",
      "demo_48 has 57 samples\n",
      "demo_49 has 59 samples\n",
      "demo_50 has 59 samples\n",
      "demo_51 has 54 samples\n",
      "demo_52 has 54 samples\n",
      "demo_53 has 51 samples\n",
      "demo_54 has 59 samples\n",
      "demo_55 has 48 samples\n",
      "demo_56 has 52 samples\n",
      "demo_57 has 50 samples\n",
      "demo_58 has 48 samples\n",
      "demo_59 has 61 samples\n",
      "demo_60 has 52 samples\n",
      "demo_61 has 64 samples\n",
      "demo_62 has 58 samples\n",
      "demo_63 has 52 samples\n",
      "demo_64 has 56 samples\n",
      "demo_65 has 66 samples\n",
      "demo_66 has 47 samples\n",
      "demo_67 has 52 samples\n",
      "demo_68 has 48 samples\n",
      "demo_69 has 46 samples\n",
      "demo_70 has 48 samples\n",
      "demo_71 has 50 samples\n",
      "demo_72 has 50 samples\n",
      "demo_73 has 47 samples\n",
      "demo_74 has 49 samples\n",
      "demo_75 has 52 samples\n",
      "demo_76 has 56 samples\n",
      "demo_77 has 55 samples\n",
      "demo_78 has 66 samples\n",
      "demo_79 has 58 samples\n",
      "demo_80 has 57 samples\n",
      "demo_81 has 61 samples\n",
      "demo_82 has 52 samples\n",
      "demo_83 has 66 samples\n",
      "demo_84 has 59 samples\n",
      "demo_85 has 64 samples\n",
      "demo_86 has 57 samples\n",
      "demo_87 has 58 samples\n",
      "demo_88 has 60 samples\n",
      "demo_89 has 67 samples\n",
      "demo_90 has 61 samples\n",
      "demo_91 has 68 samples\n",
      "demo_92 has 58 samples\n",
      "demo_93 has 66 samples\n",
      "demo_94 has 60 samples\n",
      "demo_95 has 65 samples\n",
      "demo_96 has 72 samples\n",
      "demo_97 has 68 samples\n",
      "demo_98 has 62 samples\n",
      "demo_99 has 63 samples\n",
      "demo_100 has 63 samples\n",
      "demo_101 has 64 samples\n",
      "demo_102 has 68 samples\n",
      "demo_103 has 57 samples\n",
      "demo_104 has 60 samples\n",
      "demo_105 has 58 samples\n",
      "demo_106 has 61 samples\n",
      "demo_107 has 56 samples\n",
      "demo_108 has 57 samples\n",
      "demo_109 has 64 samples\n",
      "demo_110 has 66 samples\n",
      "demo_111 has 71 samples\n",
      "demo_112 has 68 samples\n",
      "demo_113 has 62 samples\n",
      "demo_114 has 57 samples\n",
      "demo_115 has 57 samples\n",
      "demo_116 has 63 samples\n",
      "demo_117 has 60 samples\n",
      "demo_118 has 53 samples\n",
      "demo_119 has 58 samples\n",
      "demo_120 has 69 samples\n",
      "demo_121 has 59 samples\n",
      "demo_122 has 57 samples\n",
      "demo_123 has 63 samples\n",
      "demo_124 has 52 samples\n",
      "demo_125 has 74 samples\n",
      "demo_126 has 68 samples\n",
      "demo_127 has 72 samples\n",
      "demo_128 has 67 samples\n",
      "demo_129 has 62 samples\n",
      "demo_130 has 56 samples\n",
      "demo_131 has 69 samples\n",
      "demo_132 has 71 samples\n",
      "demo_133 has 60 samples\n",
      "demo_134 has 57 samples\n",
      "demo_135 has 58 samples\n",
      "demo_136 has 60 samples\n",
      "demo_137 has 55 samples\n",
      "demo_138 has 53 samples\n",
      "demo_139 has 62 samples\n",
      "demo_140 has 58 samples\n",
      "demo_141 has 63 samples\n",
      "demo_142 has 61 samples\n",
      "demo_143 has 56 samples\n",
      "demo_144 has 56 samples\n",
      "demo_145 has 57 samples\n",
      "demo_146 has 63 samples\n",
      "demo_147 has 57 samples\n",
      "demo_148 has 61 samples\n",
      "demo_149 has 53 samples\n",
      "demo_150 has 56 samples\n",
      "demo_151 has 61 samples\n",
      "demo_152 has 54 samples\n",
      "demo_153 has 59 samples\n",
      "demo_154 has 57 samples\n",
      "demo_155 has 56 samples\n",
      "demo_156 has 58 samples\n",
      "demo_157 has 63 samples\n",
      "demo_158 has 52 samples\n",
      "demo_159 has 53 samples\n",
      "demo_160 has 58 samples\n",
      "demo_161 has 52 samples\n",
      "demo_162 has 61 samples\n",
      "demo_163 has 52 samples\n",
      "demo_164 has 56 samples\n",
      "demo_165 has 54 samples\n",
      "demo_166 has 59 samples\n",
      "demo_167 has 56 samples\n",
      "demo_168 has 62 samples\n",
      "demo_169 has 63 samples\n",
      "demo_170 has 61 samples\n",
      "demo_171 has 59 samples\n",
      "demo_172 has 57 samples\n",
      "demo_173 has 61 samples\n",
      "demo_174 has 54 samples\n",
      "demo_175 has 49 samples\n",
      "demo_176 has 54 samples\n",
      "demo_177 has 49 samples\n",
      "demo_178 has 54 samples\n",
      "demo_179 has 51 samples\n",
      "demo_180 has 46 samples\n",
      "demo_181 has 51 samples\n",
      "demo_182 has 53 samples\n",
      "demo_183 has 59 samples\n",
      "demo_184 has 48 samples\n",
      "demo_185 has 54 samples\n",
      "demo_186 has 51 samples\n",
      "demo_187 has 56 samples\n",
      "demo_188 has 57 samples\n",
      "demo_189 has 60 samples\n",
      "demo_190 has 63 samples\n",
      "demo_191 has 52 samples\n",
      "demo_192 has 53 samples\n",
      "demo_193 has 57 samples\n",
      "demo_194 has 66 samples\n",
      "demo_195 has 62 samples\n",
      "demo_196 has 58 samples\n",
      "demo_197 has 54 samples\n",
      "demo_198 has 53 samples\n",
      "demo_199 has 56 samples\n"
     ]
    }
   ],
   "source": [
    "# each demonstration is named \"demo_#\" where # is a number.\n",
    "# Let's put the demonstration list in increasing episode order\n",
    "inds = np.argsort([int(elem[5:]) for elem in demos])\n",
    "demos = [demos[i] for i in inds]\n",
    "\n",
    "for ep in demos:\n",
    "    num_actions = f[\"data/{}/actions\".format(ep)].shape[0]\n",
    "    print(\"{} has {} samples\".format(ep, num_actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff998d62",
   "metadata": {},
   "source": [
    "Now, let's dig into a single trajectory to take a look at some of the quantities in each demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f7b497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep 0\n",
      "obs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at first demonstration\n",
    "demo_key = demos[0]\n",
    "demo_grp = f[\"data/{}\".format(demo_key)]\n",
    "\n",
    "# Each observation is a dictionary that maps modalities to numpy arrays, and\n",
    "# each action is a numpy array. Let's print the observations and actions for the \n",
    "# first 5 timesteps of this trajectory.\n",
    "for t in range(5):\n",
    "    print(\"timestep {}\".format(t))\n",
    "    obs_t = dict()\n",
    "    # each observation modality is stored as a subgroup\n",
    "    for k in demo_grp[\"obs\"]:\n",
    "        obs_t[k] = demo_grp[\"obs/{}\".format(k)][t] # numpy array\n",
    "    act_t = demo_grp[\"actions\"][t]\n",
    "    \n",
    "    # pretty-print observation and action using json\n",
    "    obs_t_pp = { k : obs_t[k].tolist() for k in obs_t }\n",
    "    print(\"obs\")\n",
    "    print(json.dumps(obs_t_pp, indent=4))\n",
    "    print(\"action\")\n",
    "    print(act_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "552be387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of first ten actions (10, 7)\n",
      "shape of all actions (66, 7)\n"
     ]
    }
   ],
   "source": [
    "# we can also grab multiple timesteps at once directly, or even the full trajectory at once\n",
    "first_ten_actions = demo_grp[\"actions\"][:10]\n",
    "print(\"shape of first ten actions {}\".format(first_ten_actions.shape))\n",
    "all_actions = demo_grp[\"actions\"][:]\n",
    "print(\"shape of all actions {}\".format(all_actions.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "57976238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "# the trajectory also contains the next observations under \"next_obs\", \n",
    "# for convenient use in a batch (offline) RL pipeline. Let's verify\n",
    "# that \"next_obs\" and \"obs\" are offset by 1.\n",
    "for k in demo_grp[\"obs\"]:\n",
    "    # obs_{t+1} == next_obs_{t}\n",
    "    assert(np.allclose(demo_grp[\"obs\"][k][1:], demo_grp[\"next_obs\"][k][:-1]))\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "51ab4a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dones\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\n",
      "rewards\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# we also have \"done\" and \"reward\" information stored in each trajectory.\n",
    "# In this case, we have sparse rewards that indicate task completion at\n",
    "# that timestep.\n",
    "dones = demo_grp[\"dones\"][:]\n",
    "rewards = demo_grp[\"rewards\"][:]\n",
    "print(\"dones\")\n",
    "print(dones)\n",
    "print(\"\")\n",
    "print(\"rewards\")\n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "360df27c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to synchronously open attribute (can't locate attribute: 'model_file')\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# each demonstration also contains metadata\u001b[39;00m\n\u001b[1;32m      2\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m demo_grp\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;66;03m# number of samples in this trajectory\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m mujoco_xml_file \u001b[38;5;241m=\u001b[39m \u001b[43mdemo_grp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# mujoco XML file for this demonstration\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(mujoco_xml_file)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/proj/vondrick3/sruthi/miniconda3/envs/robomimic/lib/python3.8/site-packages/h5py/_hl/attrs.py:56\u001b[0m, in \u001b[0;36mAttributeManager.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;129m@with_phil\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Read the value of an attribute.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[43mh5a\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     shape \u001b[38;5;241m=\u001b[39m attr\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# shape is None for empty dataspaces\u001b[39;00m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5a.pyx:80\u001b[0m, in \u001b[0;36mh5py.h5a.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to synchronously open attribute (can't locate attribute: 'model_file')\""
     ]
    }
   ],
   "source": [
    "# each demonstration also contains metadata\n",
    "num_samples = demo_grp.attrs[\"num_samples\"] # number of samples in this trajectory\n",
    "mujoco_xml_file = demo_grp.attrs[\"model_file\"] # mujoco XML file for this demonstration\n",
    "print(mujoco_xml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10f98f",
   "metadata": {},
   "source": [
    "Finally, let's take a look at some global metadata present in the file. The hdf5 file stores environment metadata which is a convenient way to understand which simulation environment (task) the dataset was collected on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3b579caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Env Meta ====\n",
      "{\n",
      "    \"type\": 3,\n",
      "    \"env_name\": \"RealPandaEnv\",\n",
      "    \"env_kwargs\": {\n",
      "        \"world\": \"Real\",\n",
      "        \"robot\": \"panda\",\n",
      "        \"controlType\": \"EEPosture\",\n",
      "        \"config\": {\n",
      "            \"world\": {\n",
      "                \"type\": \"Real\",\n",
      "                \"robot\": \"panda\",\n",
      "                \"controlType\": \"EEPosture\"\n",
      "            },\n",
      "            \"sim_params\": {\n",
      "                \"time_step\": 0.001,\n",
      "                \"control_freq\": 2,\n",
      "                \"steps_per_action\": 40,\n",
      "                \"MAX_STEPS\": 500\n",
      "            },\n",
      "            \"redis\": {\n",
      "                \"host\": \"172.16.0.1\",\n",
      "                \"port\": 6379\n",
      "            },\n",
      "            \"redis_ws\": {\n",
      "                \"host\": \"localhost\",\n",
      "                \"port\": 6379\n",
      "            },\n",
      "            \"policy_freq\": 20,\n",
      "            \"control_freq\": 1000,\n",
      "            \"panda\": {\n",
      "                \"arm\": {\n",
      "                    \"path\": \"robot/franka_panda/panda.urdf\",\n",
      "                    \"pose\": [\n",
      "                        0,\n",
      "                        0,\n",
      "                        0\n",
      "                    ],\n",
      "                    \"orn\": [\n",
      "                        0,\n",
      "                        0,\n",
      "                        0\n",
      "                    ],\n",
      "                    \"is_static\": true\n",
      "                },\n",
      "                \"base\": \"None\",\n",
      "                \"neutral_joint_angles\": [\n",
      "                    0.0,\n",
      "                    -0.3135,\n",
      "                    0.0,\n",
      "                    -2.515,\n",
      "                    0.0,\n",
      "                    2.226,\n",
      "                    0.87\n",
      "                ],\n",
      "                \"limb_joint_names\": [\n",
      "                    \"panda_link0\",\n",
      "                    \"panda_link1\",\n",
      "                    \"panda_link2\",\n",
      "                    \"panda_link3\",\n",
      "                    \"panda_link4\",\n",
      "                    \"panda_link5\",\n",
      "                    \"panda_link6\"\n",
      "                ],\n",
      "                \"limb_height\": 0.9,\n",
      "                \"end_effector_name\": \"right_hand\",\n",
      "                \"l_finger_name\": \"panda_leftfinger\",\n",
      "                \"r_finger_name\": \"panda_rightfinger\",\n",
      "                \"l_finger_tip_name\": \"r_gripper_l_finger_tip\",\n",
      "                \"r_finger_tip_name\": \"r_gripper_r_finger_tip\",\n",
      "                \"limb_max_velocity_ratio\": 0.01,\n",
      "                \"limb_position_threshold\": 0.00872664,\n",
      "                \"limb_velocity_threshold\": 0.75,\n",
      "                \"end_effector_step\": 0.02\n",
      "            },\n",
      "            \"safenet\": {\n",
      "                \"use_safenet\": false,\n",
      "                \"lower\": [\n",
      "                    0.25,\n",
      "                    -0.25,\n",
      "                    -0.03\n",
      "                ],\n",
      "                \"upper\": [\n",
      "                    0.7,\n",
      "                    0.25,\n",
      "                    0.65\n",
      "                ]\n",
      "            },\n",
      "            \"panda_controller\": {\n",
      "                \"Real\": {\n",
      "                    \"EEImpedance\": {\n",
      "                        \"kp\": [\n",
      "                            150,\n",
      "                            150,\n",
      "                            150,\n",
      "                            70.0,\n",
      "                            70.0,\n",
      "                            70.0\n",
      "                        ],\n",
      "                        \"kv\": [\n",
      "                            30.0,\n",
      "                            30.0,\n",
      "                            30.0,\n",
      "                            25.0,\n",
      "                            25.0,\n",
      "                            25.0\n",
      "                        ],\n",
      "                        \"damping\": 1.0,\n",
      "                        \"input_max\": 1.0,\n",
      "                        \"input_min\": -1.0,\n",
      "                        \"output_max\": [\n",
      "                            0.1,\n",
      "                            0.1,\n",
      "                            0.1,\n",
      "                            0.9,\n",
      "                            0.9,\n",
      "                            1.0\n",
      "                        ],\n",
      "                        \"output_min\": [\n",
      "                            -0.1,\n",
      "                            -0.1,\n",
      "                            -0.1,\n",
      "                            -0.9,\n",
      "                            -0.9,\n",
      "                            -1.0\n",
      "                        ]\n",
      "                    },\n",
      "                    \"JointVelocity\": {\n",
      "                        \"kv\": 10.0,\n",
      "                        \"input_max\": 1.0,\n",
      "                        \"input_min\": -1.0,\n",
      "                        \"output_max\": 1.0,\n",
      "                        \"output_min\": -1.0\n",
      "                    },\n",
      "                    \"JointImpedance\": {\n",
      "                        \"kp\": [\n",
      "                            300.0,\n",
      "                            300.0,\n",
      "                            300.0,\n",
      "                            300.0,\n",
      "                            250.0,\n",
      "                            150.0,\n",
      "                            150.0\n",
      "                        ],\n",
      "                        \"kv\": [\n",
      "                            20.0,\n",
      "                            20.0,\n",
      "                            20.0,\n",
      "                            20.0,\n",
      "                            15.0,\n",
      "                            12.0,\n",
      "                            15.0\n",
      "                        ],\n",
      "                        \"damping\": 1.0,\n",
      "                        \"input_max\": 1.0,\n",
      "                        \"input_min\": -1.0,\n",
      "                        \"output_max\": 1.0,\n",
      "                        \"output_min\": -1.0\n",
      "                    },\n",
      "                    \"JointTorque\": {\n",
      "                        \"input_max\": 1.0,\n",
      "                        \"input_min\": -1.0,\n",
      "                        \"output_max\": 5.0,\n",
      "                        \"output_min\": -5.0\n",
      "                    },\n",
      "                    \"EEPosture\": {\n",
      "                        \"kp\": [\n",
      "                            100,\n",
      "                            100,\n",
      "                            100,\n",
      "                            40.0,\n",
      "                            40.0,\n",
      "                            40.0\n",
      "                        ],\n",
      "                        \"damping\": 1.0,\n",
      "                        \"posture\": [\n",
      "                            0.0,\n",
      "                            -0.3135,\n",
      "                            0.0,\n",
      "                            -2.515,\n",
      "                            0.0,\n",
      "                            2.226,\n",
      "                            0.87\n",
      "                        ],\n",
      "                        \"posture_gain\": [\n",
      "                            5.0,\n",
      "                            5.0,\n",
      "                            5.0,\n",
      "                            4.0,\n",
      "                            3.0,\n",
      "                            3.0,\n",
      "                            3.0\n",
      "                        ],\n",
      "                        \"input_max\": 1.0,\n",
      "                        \"input_min\": -1.0,\n",
      "                        \"output_max\": [\n",
      "                            0.15,\n",
      "                            0.15,\n",
      "                            0.15,\n",
      "                            0.75,\n",
      "                            0.75,\n",
      "                            0.75\n",
      "                        ],\n",
      "                        \"output_min\": [\n",
      "                            -0.15,\n",
      "                            -0.15,\n",
      "                            -0.15,\n",
      "                            -0.75,\n",
      "                            -0.75,\n",
      "                            -0.75\n",
      "                        ]\n",
      "                    }\n",
      "                },\n",
      "                \"interpolator_pos\": {\n",
      "                    \"type\": \"linear\",\n",
      "                    \"order\": 1,\n",
      "                    \"max_dx\": 0.2,\n",
      "                    \"ramp_ratio\": 0.2\n",
      "                },\n",
      "                \"interpolator_ori\": {\n",
      "                    \"type\": \"linear\",\n",
      "                    \"fraction\": 0.2\n",
      "                },\n",
      "                \"Bullet\": {\n",
      "                    \"EEImpedance\": {\n",
      "                        \"kp\": [\n",
      "                            100,\n",
      "                            100,\n",
      "                            100,\n",
      "                            60.0,\n",
      "                            60.0,\n",
      "                            60.0\n",
      "                        ],\n",
      "                        \"kv\": [\n",
      "                            20.0,\n",
      "                            20.0,\n",
      "                            20.0,\n",
      "                            10.0,\n",
      "                            10.0,\n",
      "                            10.0\n",
      "                        ],\n",
      "                        \"damping\": 1.0,\n",
      "                        \"input_max\": 1.0,\n",
      "                        \"input_min\": -1.0,\n",
      "                        \"output_max\": 1.0,\n",
      "                        \"output_min\": -1.0\n",
      "                    },\n",
      "                    \"JointVelocity\": {\n",
      "                        \"kv\": 10.0,\n",
      "                        \"input_max\": 1.0,\n",
      "                        \"input_min\": -1.0,\n",
      "                        \"output_max\": 1.0,\n",
      "                        \"output_min\": -1.0\n",
      "                    },\n",
      "                    \"JointImpedance\": {\n",
      "                        \"kp\": [\n",
      "                            300.0,\n",
      "                            300.0,\n",
      "                            300.0,\n",
      "                            300.0,\n",
      "                            250.0,\n",
      "                            150.0,\n",
      "                            150.0\n",
      "                        ],\n",
      "                        \"kv\": [\n",
      "                            20.0,\n",
      "                            20.0,\n",
      "                            20.0,\n",
      "                            20.0,\n",
      "                            15.0,\n",
      "                            12.0,\n",
      "                            15.0\n",
      "                        ],\n",
      "                        \"damping\": 1.0,\n",
      "                        \"input_max\": 1.0,\n",
      "                        \"input_min\": -1.0,\n",
      "                        \"output_max\": 1.0,\n",
      "                        \"output_min\": -1.0\n",
      "                    },\n",
      "                    \"JointTorque\": {\n",
      "                        \"input_max\": 1.0,\n",
      "                        \"input_min\": -1.0,\n",
      "                        \"output_max\": 5.0,\n",
      "                        \"output_min\": -5.0\n",
      "                    },\n",
      "                    \"EEPosture\": {\n",
      "                        \"kp\": [\n",
      "                            100,\n",
      "                            100,\n",
      "                            100,\n",
      "                            60.0,\n",
      "                            60.0,\n",
      "                            60.0\n",
      "                        ],\n",
      "                        \"kv\": [\n",
      "                            20.0,\n",
      "                            20.0,\n",
      "                            20.0,\n",
      "                            10.0,\n",
      "                            10.0,\n",
      "                            10.0\n",
      "                        ],\n",
      "                        \"damping\": 1.0,\n",
      "                        \"posture\": [\n",
      "                            0.0,\n",
      "                            -0.3135,\n",
      "                            0.0,\n",
      "                            -2.515,\n",
      "                            0.0,\n",
      "                            2.226,\n",
      "                            0.87\n",
      "                        ],\n",
      "                        \"posture_gain\": [\n",
      "                            5.0,\n",
      "                            5.0,\n",
      "                            5.0,\n",
      "                            4.0,\n",
      "                            3.0,\n",
      "                            3.0,\n",
      "                            3.0\n",
      "                        ],\n",
      "                        \"input_max\": 1.0,\n",
      "                        \"input_min\": -1.0,\n",
      "                        \"output_max\": 1.0,\n",
      "                        \"output_min\": -1.0\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            \"gripper\": {\n",
      "                \"close_value\": 0.6,\n",
      "                \"open_value\": 0.99\n",
      "            },\n",
      "            \"env\": {\n",
      "                \"observation_space\": {\n",
      "                    \"low\": [\n",
      "                        -2.0,\n",
      "                        -2.0,\n",
      "                        -2.0,\n",
      "                        0,\n",
      "                        0,\n",
      "                        0,\n",
      "                        0\n",
      "                    ],\n",
      "                    \"high\": [\n",
      "                        2.0,\n",
      "                        2.0,\n",
      "                        2.0,\n",
      "                        1.0,\n",
      "                        1.0,\n",
      "                        1.0,\n",
      "                        1.0\n",
      "                    ]\n",
      "                },\n",
      "                \"action_space\": {\n",
      "                    \"low\": [\n",
      "                        -1,\n",
      "                        -1,\n",
      "                        -1,\n",
      "                        -1,\n",
      "                        -1,\n",
      "                        -1,\n",
      "                        -1\n",
      "                    ],\n",
      "                    \"high\": [\n",
      "                        1,\n",
      "                        1,\n",
      "                        1,\n",
      "                        1,\n",
      "                        1,\n",
      "                        1,\n",
      "                        1\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_meta = json.loads(f[\"data\"].attrs[\"env_args\"])\n",
    "# note: we could also have used the following function:\n",
    "# env_meta = FileUtils.get_env_metadata_from_dataset(dataset_path=dataset_path)\n",
    "print(\"==== Env Meta ====\")\n",
    "print(json.dumps(env_meta, indent=4))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b395453a",
   "metadata": {},
   "source": [
    "## Visualizing demonstration trajectories\n",
    "\n",
    "Finally, let's play some of these demonstrations back in the simulation environment to easily visualize the data that was collected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613ab93",
   "metadata": {},
   "source": [
    "It turns out that the environment metadata stored in the hdf5 allows us to easily create a simulation environment that is consistent with the way the dataset was collected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9c98068e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'ig_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrobomimic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv_utils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mEnvUtils\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# create simulation environment from environment metedata\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mEnvUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_env_from_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# no on-screen rendering\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender_offscreen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# off-screen rendering to support rendering video frames\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/proj/vondrick3/sruthi/robots/robomimic/robomimic/utils/env_utils.py:229\u001b[0m, in \u001b[0;36mcreate_env_from_metadata\u001b[0;34m(env_meta, env_name, render, render_offscreen, use_image_obs, use_depth_obs)\u001b[0m\n\u001b[1;32m    226\u001b[0m env_type \u001b[38;5;241m=\u001b[39m get_env_type(env_meta\u001b[38;5;241m=\u001b[39menv_meta)\n\u001b[1;32m    227\u001b[0m env_kwargs \u001b[38;5;241m=\u001b[39m env_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 229\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_env\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender_offscreen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender_offscreen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_image_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_image_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_depth_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_depth_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43menv_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m check_env_version(env, env_meta)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m env\n",
      "File \u001b[0;32m/proj/vondrick3/sruthi/robots/robomimic/robomimic/utils/env_utils.py:174\u001b[0m, in \u001b[0;36mcreate_env\u001b[0;34m(env_type, env_name, render, render_offscreen, use_image_obs, use_depth_obs, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# note: pass @postprocess_visual_obs True, to make sure images are processed for network inputs\u001b[39;00m\n\u001b[1;32m    173\u001b[0m env_class \u001b[38;5;241m=\u001b[39m get_env_class(env_type\u001b[38;5;241m=\u001b[39menv_type)\n\u001b[0;32m--> 174\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43menv_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender_offscreen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender_offscreen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_image_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_image_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_depth_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_depth_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpostprocess_visual_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated environment with name \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(env_name))\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction size is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(env\u001b[38;5;241m.\u001b[39maction_dimension))\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'ig_config'"
     ]
    }
   ],
   "source": [
    "import robomimic.utils.env_utils as EnvUtils\n",
    "\n",
    "# create simulation environment from environment metedata\n",
    "env = EnvUtils.create_env_from_metadata(\n",
    "    env_meta=env_meta, \n",
    "    render=False,            # no on-screen rendering\n",
    "    render_offscreen=True,   # off-screen rendering to support rendering video frames\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "595a47d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['robot0_eef_pos']\n",
      "using obs modality: rgb with keys: []\n"
     ]
    }
   ],
   "source": [
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "\n",
    "# We normally need to make sure robomimic knows which observations are images (for the\n",
    "# data processing pipeline). This is usually inferred from your training config, but\n",
    "# since we are just playing back demonstrations, we just need to initialize robomimic\n",
    "# with a dummy spec.\n",
    "dummy_spec = dict(\n",
    "    obs=dict(\n",
    "            low_dim=[\"robot0_eef_pos\"],\n",
    "            rgb=[],\n",
    "        ),\n",
    ")\n",
    "ObsUtils.initialize_obs_utils_with_obs_specs(obs_modality_specs=dummy_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d997cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "# prepare to write playback trajectories to video\n",
    "video_path = os.path.join(download_folder, \"playback.mp4\")\n",
    "video_writer = imageio.get_writer(video_path, fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def playback_trajectory(demo_key):\n",
    "    \"\"\"\n",
    "    Simple helper function to playback the trajectory stored under the hdf5 group @demo_key and\n",
    "    write frames rendered from the simulation to the active @video_writer.\n",
    "    \"\"\"\n",
    "    \n",
    "    # robosuite datasets store the ground-truth simulator states under the \"states\" key.\n",
    "    # We will use the first one, alone with the model xml, to reset the environment to\n",
    "    # the initial configuration before playing back actions.\n",
    "    init_state = f[\"data/{}/states\".format(demo_key)][0]\n",
    "    model_xml = f[\"data/{}\".format(demo_key)].attrs[\"model_file\"]\n",
    "    initial_state_dict = dict(states=init_state, model=model_xml)\n",
    "    \n",
    "    # reset to initial state\n",
    "    env.reset_to(initial_state_dict)\n",
    "    \n",
    "    # playback actions one by one, and render frames\n",
    "    actions = f[\"data/{}/actions\".format(demo_key)][:]\n",
    "    for t in range(actions.shape[0]):\n",
    "        env.step(actions[t])\n",
    "        video_img = env.render(mode=\"rgb_array\", height=512, width=512, camera_name=\"agentview\")\n",
    "        video_writer.append_data(video_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playback the first 5 demos\n",
    "for ep in demos[5:10]:\n",
    "    print(\"Playing back demo key: {}\".format(ep))\n",
    "    playback_trajectory(ep)\n",
    "\n",
    "# done writing video\n",
    "video_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the trajectories!\n",
    "from IPython.display import Video\n",
    "Video(video_path, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a97e5c-1640-47f1-9948-85d2dc1d9177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
